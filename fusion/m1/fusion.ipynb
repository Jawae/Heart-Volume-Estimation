{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 3007)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import InputLayer, Conv2DLayer, MaxPool2DLayer, DenseLayer, GlobalPoolLayer, Upscale2DLayer\n",
    "from lasagne.layers import ElemwiseSumLayer, NonlinearityLayer, SliceLayer, ConcatLayer, ScaleLayer\n",
    "from lasagne.layers import dropout, batch_norm\n",
    "from lasagne.nonlinearities import rectify, softmax, sigmoid\n",
    "from lasagne.init import GlorotNormal, GlorotUniform, HeUniform, HeNormal\n",
    "from lasagne.objectives import squared_error, categorical_crossentropy, categorical_accuracy, binary_accuracy\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import random\n",
    "import theano\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import benchmark as bm\n",
    "\n",
    "from fcn1.adapter import adapter as adapter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_volume(area, location, resolution):\n",
    "    def _step(idx_, prior_result_, area_, location_, resolution_):\n",
    "        area1 = area_[idx_] * T.prod(resolution_[idx_])\n",
    "        area2 = area_[idx_ + 1] * T.prod(resolution_[idx_ + 1])\n",
    "        h = location_[idx_ + 1] - location_[idx_]\n",
    "        volume = (area1 + area2 )* np.prod(fixed_size).astype('float32') * h / 2.0 / 1000\n",
    "        return prior_result_ + volume\n",
    "\n",
    "    predict_V_list, _ = theano.scan(fn=_step,\n",
    "                              outputs_info = np.array([0.]).astype('float32'),\n",
    "                              sequences = T.arange(1000),\n",
    "                              non_sequences = [area, location, resolution],\n",
    "                              n_steps = location.shape[0] - 1)\n",
    "    predict_V = predict_V_list[-1]\n",
    "    return predict_V[0]\n",
    "\n",
    "def stage3_load_single_record(file_path, fixed_size):\n",
    "    data = np.load(file_path).item()\n",
    "    patch_list = data['patchStack']\n",
    "    location_list = np.array(data['SliceLocation'])\n",
    "    resolution = np.array(data['PixelSpacing'])\n",
    "    resized_resolution_list = []\n",
    "    resized_patch_list = []\n",
    "    for patch in patch_list:\n",
    "        resized_resolution_list.append(\n",
    "            (resolution[0] / fixed_size[0] * patch.shape[0], resolution[1] / fixed_size[1] * patch.shape[1]))\n",
    "        resized_patch_list.append(cv2.resize(patch, fixed_size))\n",
    "    \n",
    "    resized_patch_list = np.array(resized_patch_list, dtype='float32')[:, None, :, :]\n",
    "    location_list = np.array(location_list, dtype='float32')\n",
    "    resized_resolution_list = np.array(resized_resolution_list, dtype='float32')\n",
    "    return resized_patch_list, location_list, resized_resolution_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_size = (48, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read train and val volume data\n",
    "volume_csv_path = '../../clean/stage3/train.csv'\n",
    "volume_csv = pd.read_csv(volume_csv_path)\n",
    "volume_data = np.array(volume_csv.iloc[:, 1:3])\n",
    "rows = volume_data.shape[0]\n",
    "volume_data = np.repeat(volume_data.flatten(), 4).astype('float32')\n",
    "\n",
    "# read train and val patch, location and resolution\n",
    "root_dir = '../../clean/stage3'\n",
    "min_root_dir = os.path.join(root_dir, 'min')\n",
    "max_root_dir = os.path.join(root_dir, 'max')\n",
    "x_data = []\n",
    "location_data = []\n",
    "resolution_data = []\n",
    "for i in range(1, rows + 1):\n",
    "    min_full_path = os.path.join(min_root_dir, str(i) + '.npy')\n",
    "    max_full_path = os.path.join(max_root_dir, str(i) + '.npy')\n",
    "    paths = [min_full_path, max_full_path]\n",
    "    for path in paths:\n",
    "        x_data_single, location_data_single, resolution_data_single = stage3_load_single_record(path, fixed_size)\n",
    "        x_data.append(x_data_single)\n",
    "        location_data.append(location_data_single)\n",
    "        resolution_data.append(resolution_data_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "snapshot 96.npz not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2f7822074e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# all adapters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0madapters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0madapters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'96.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# input tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/liao/data/kaggle/fusion/fcn1/adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inner_size, snapshot_full_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"snapshot {} not found\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnapshot_full_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: snapshot 96.npz not found"
     ]
    }
   ],
   "source": [
    "location = T.vector('location')\n",
    "resolution = T.matrix('resolution')\n",
    "target_volume = T.fscalar('volume')\n",
    "\n",
    "# all adapters\n",
    "adapters = []\n",
    "adapters.append(adapter1((48, 48), '96.npz'))\n",
    "\n",
    "# input tensor\n",
    "pred = T.tensor4('pred')\n",
    "area = T.mean(pred, axis=[1, 2, 3])\n",
    "pred_volume = build_volume(area, location, resolution)\n",
    "loss = T.abs_(pred_volume - target_volume).mean() / 600\n",
    "\n",
    "val_fn = theano.function(\n",
    "    [pred, location, resolution, target_volume],\n",
    "    loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"-----------------predicting---------------------\")\n",
    "test_losses = []\n",
    "for j in range(len(x_data)):\n",
    "    x_e = x_data[j].astype('float32')\n",
    "    preds = []\n",
    "    for adapter in adapters:\n",
    "        preds.append(adapter.convert(x_e))\n",
    "    pred_e = np.concatenate(preds, axis=1)\n",
    "    location_e = location_data[j].astype('float32')\n",
    "    resolution_e = resolution_data[j].astype('float32')\n",
    "    volume_e = volume_data[j].astype('float32')\n",
    "    loss = val_fn(pred_e, location_e, resolution_e, volume_e)\n",
    "    test_losses.append(loss)\n",
    "print(\"total #samples: {}, loss: {}\".format(len(x_data), np.mean(test_losses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
